{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Heuristically counting overcommitment/undercommitment rate from the experiments.",
   "id": "4a8d67b994e76249"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from redel.utils import read_jsonl\n",
    "\n",
    "# define base experiments path\n",
    "EXPERIMENTS = Path(\"/Users/andrew/Desktop/Code/kanpai/experiments\")\n",
    "\n",
    "\n",
    "def is_overcommitted(fp, overcommitment_threshold):\n",
    "    \"\"\"A system is overcommitted if it has <= overcommitment_threshold nodes\"\"\"\n",
    "    with open(fp) as f:\n",
    "        state = json.load(f)\n",
    "    return len(state[\"state\"]) <= overcommitment_threshold\n",
    "\n",
    "\n",
    "def is_undercommitted(fp, undercommitment_threshold):\n",
    "    \"\"\"A system is undercommitted if it has any undercommitment_threshold len chain of nodes with 0 or 1 children\"\"\"\n",
    "    with open(fp) as f:\n",
    "        state = json.load(f)\n",
    "\n",
    "    nodes = {node[\"id\"]: node for node in state[\"state\"]}\n",
    "    root = next(node for node in state[\"state\"] if node[\"depth\"] == 0)\n",
    "\n",
    "    # DFS into each node, when reaching leaf mark as T/F if accumulated 1-child parents >= undercommitment_threshold\n",
    "    # then every node's T/F value = any(children)\n",
    "    # return root node's value\n",
    "    def uc_search(node, chain):\n",
    "        is_chain = len(node[\"children\"]) <= 1\n",
    "        if not node[\"children\"]:\n",
    "            return chain + 1 >= undercommitment_threshold\n",
    "\n",
    "        is_uc = False\n",
    "        for child_id in node[\"children\"]:\n",
    "            child = nodes[child_id]\n",
    "            is_uc = is_uc or uc_search(child, chain + 1 if is_chain else 0)\n",
    "        return is_uc\n",
    "\n",
    "    return uc_search(root, 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CommitmentResult:\n",
    "    oc_count: int\n",
    "    uc_count: int\n",
    "    samples: int\n",
    "    oc_ids: list[str]\n",
    "    uc_ids: list[str]\n",
    "\n",
    "\n",
    "def count_system(fp, overcommitment_threshold=2, undercommitment_threshold=3):\n",
    "    if not fp.exists():\n",
    "        return\n",
    "    # get all state paths in system\n",
    "    state_paths = []\n",
    "    for result in read_jsonl(fp / \"results.jsonl\"):\n",
    "        state_paths.append(fp / Path(result[\"log_dir\"]).stem / \"state.json\")\n",
    "\n",
    "    n = len(state_paths)\n",
    "    oc_count = 0\n",
    "    uc_count = 0\n",
    "    oc_ids = []\n",
    "    uc_ids = []\n",
    "    for state_path in state_paths:\n",
    "        if is_overcommitted(state_path, overcommitment_threshold):\n",
    "            oc_count += 1\n",
    "            oc_ids.append(state_path.parent.name)\n",
    "        if is_undercommitted(state_path, undercommitment_threshold):\n",
    "            uc_count += 1\n",
    "            uc_ids.append(state_path.parent.name)\n",
    "\n",
    "    print(f\"========== {fp} ==========\")\n",
    "    print(f\"Overcommitment rate: {oc_count / n} ({oc_count} / {n})\")\n",
    "    print(f\"Undercommitment rate: {uc_count / n} ({uc_count} / {n})\")\n",
    "    return CommitmentResult(oc_count=oc_count, uc_count=uc_count, samples=n, oc_ids=oc_ids, uc_ids=uc_ids)"
   ],
   "id": "ef27edcba63c966a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fo = count_system(EXPERIMENTS / Path(\"fanoutqa/dev/trial2/full\"))\n",
    "tp = count_system(EXPERIMENTS / Path(\"travelplanner/validation/full\"))\n",
    "wa = count_system(EXPERIMENTS / Path(\"webarena/test/full\"))"
   ],
   "id": "850b6dd52571f5ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "oc_total = fo.oc_count + tp.oc_count + wa.oc_count\n",
    "uc_total = fo.uc_count + tp.uc_count + wa.uc_count\n",
    "n_total = fo.samples + tp.samples + wa.samples\n",
    "\n",
    "print(f\"Total overcommitment rate: {oc_total / n_total} ({oc_total} / {n_total})\")\n",
    "print(f\"Total undercommitment rate: {uc_total / n_total} ({uc_total} / {n_total})\")"
   ],
   "id": "47fef150993f75f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for system in [\n",
    "    \"full\",\n",
    "    # \"root-fc\",\n",
    "    # \"baseline\",\n",
    "    # \"small-leaf\",\n",
    "    \"small-all\",\n",
    "    # \"small-baseline\",\n",
    "    # \"short-context\",\n",
    "    # \"short-baseline\",\n",
    "]:\n",
    "    for benchmark in [\"fanoutqa/dev/trial2\", \"travelplanner/validation\", \"webarena/test\"]:\n",
    "        count_system(EXPERIMENTS / benchmark / system)"
   ],
   "id": "47abc1c7359a1263",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Getting score conditional on over/undercommitted results.",
   "id": "815008f1f9b14352"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# foqa\n",
    "benchmark = \"fanoutqa/dev/trial2\"\n",
    "system = \"full\"\n",
    "\n",
    "with open(EXPERIMENTS / benchmark / system / \"score.json\") as f:\n",
    "    fo_scores = json.load(f)\n",
    "\n",
    "commitment = count_system(EXPERIMENTS / benchmark / system)\n",
    "bad_ids = set(commitment.uc_ids) | set(commitment.uc_ids)\n",
    "\n",
    "good_scores = [s for s in fo_scores[\"raw\"] if s[\"question_id\"] in bad_ids]\n",
    "\n",
    "good_loose = sum(s[\"acc\"] for s in good_scores) / len(good_scores)\n",
    "good_gpt = sum(s[\"gpt\"] for s in good_scores) / len(good_scores)\n",
    "\n",
    "print(\"========== FOQA ==========\")\n",
    "print(f\"Full Loose: {fo_scores['acc']['loose']}\")\n",
    "print(f\"Full GPT: {fo_scores['gpt']}\")\n",
    "print(f\"Filtered Loose: {good_loose}\")\n",
    "print(f\"Filtered GPT: {good_gpt}\")\n",
    "\n",
    "# for system in [\"full\", \"small-leaf\"]:"
   ],
   "id": "3c2bbe7795269ede",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(bad_ids)",
   "id": "bd6010946bd5a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bad_ids",
   "id": "f340fb0d938941bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# foqa\n",
    "benchmark = \"fanoutqa/dev/trial2\"\n",
    "system = \"full\"\n",
    "\n",
    "with open(EXPERIMENTS / benchmark / system / \"score.json\") as f:\n",
    "    fo_scores = json.load(f)\n",
    "\n",
    "fails = [s for s in fo_scores[\"raw\"] if s[\"gpt\"] == 0]\n",
    "fail_ids = [s['question_id'] for s in fails]\n",
    "\n",
    "\n",
    "# for system in [\"full\", \"small-leaf\"]:"
   ],
   "id": "82fdd30a8bcf05cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "fails",
   "id": "93e107e03bc664d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bfd467928a4a310c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
